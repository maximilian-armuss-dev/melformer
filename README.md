# ğŸ¶ Melformer  
ğŸš§ **Heavily Under Construction** â€“ This project is in early development. Expect broken things, half-finished thoughts, and lots of experimentation.

## ğŸ“Œ Overview

**Melformer** is a research-driven music generation project that combines the representational power of a **VQ-VAE** with the sequential modeling capabilities of a **transformer**.

Instead of working with raw audio directly, Melformer introduces a custom audio format (`.tiaf`) that stores a fixed number of samples per **beat**â€”not per second. This beat-aligned representation allows the model to treat audio like a sequence of tokens, similar to words in NLP.

## ğŸ§  Ideas & Theory

### ğŸ¼ The `.tiaf` Format
Traditional `.wav` files store **samples per second (e.g. 44,100Hz)**. This causes token misalignment when tempo changes.

`.tiaf` redefines time:  
- Stores a 40k samples **per beat**
- BPM-independent representation
- Makes musical phrases directly tokenizable

Each **beat becomes a token**, forming a clean sequence ideal for transformers.

### Drawbacks

40k samples per token is a lot of data â†’ **training and inference would take ages!**

### ğŸ§± Model Architecture

In order to save computations while keeping the most relevant features of the original audio data, we leverage the power of a **VQ-VAE** as follows:

![Model Architecture](melformer.svg)

### ğŸ“ Training Plan

1. **Train VQ-VAE** on `.tiaf` audio until convergence  
2. **Freeze encoder and decoder**  
3. Insert **transformer** between them  
4. Train transformer **autoregressively**  

## ğŸ“ Project Structure

    melformer/
    â”‚
    â”œâ”€â”€ configs/
    â”‚   â””â”€â”€ transformer.json                # Config file for Transformer model
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ test_in/                        # Raw .wav files for testing
    â”‚   â”‚   â””â”€â”€ [example_loops].wav
    â”‚   â””â”€â”€ test_out/                       # Placeholder for processed output
    â”‚
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ audio_classes/
    â”‚   â”‚   â”œâ”€â”€ tiaf.py                     # Convert .wav <-> .tiaf format
    â”‚   â”‚   â””â”€â”€ wav.py                      # WAV loading & handling utilities
    â”‚   â”‚
    â”‚   â”œâ”€â”€ dataset/
    â”‚   â”‚   â””â”€â”€ tokenicer_dataset.py        # Dataset class for tokenized audio
    â”‚   â”‚
    â”‚   â”œâ”€â”€ melformer/
    â”‚   â”‚   â”œâ”€â”€ encoder/
    â”‚   â”‚   â”‚   â”œâ”€â”€ encoder.py            
    â”‚   â”‚   â”‚   â””â”€â”€ encoder_blocks.py
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â”€ decoder/
    â”‚   â”‚   â”‚   â”œâ”€â”€ decoder.py
    â”‚   â”‚   â”‚   â””â”€â”€ decoder_blocks.py
    â”‚   â”‚   â”‚
    â”‚   â”‚   â””â”€â”€ transformer/
    â”‚   â”‚       â”œâ”€â”€ classifier.py           # Final linear layer
    â”‚   â”‚       â”œâ”€â”€ gqa.py                  # Grouped-Query attention
    â”‚   â”‚       â”œâ”€â”€ kvcache.py              
    â”‚   â”‚       â”œâ”€â”€ mlp.py                  # Multi-Layer-Perceptron (SwiGLU feedforward network)
    â”‚   â”‚       â”œâ”€â”€ rms_norm.py             # Root-Mean-Square norm
    â”‚   â”‚       â”œâ”€â”€ rope.py                 # Rotary positional embeddings
    â”‚   â”‚       â”œâ”€â”€ transformer_block.py    # Transformer modules with LLaMa-2 architecture
    â”‚   â”‚       â””â”€â”€ transformer_model.py    # Overall model
    â”‚   â”‚
    â”‚   â””â”€â”€ util/
    â”‚       â”œâ”€â”€ config_loader.py            # Loads and parses config files
    â”‚       â”œâ”€â”€ fft_test.py                 # Test for FFT operations
    â”‚       â””â”€â”€ stft.py                     # Short-time Fourier Transform tools
    â”‚
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ environment.yml
    â””â”€â”€ README.md

## ğŸ› ï¸ Setup

Coming soon â€“ once things are working.  

## ğŸ“¬ Contact

If you're curious, want to collaborate, or just geek out over music + AI, feel free to reach out!
